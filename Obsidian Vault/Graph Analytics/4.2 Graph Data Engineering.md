## Life Cycle dei Big Data
- **Collect**: Dati da svariate sorgenti sono raggruppati e collezionati.
- **Store**: I dati sono memorizzati in maniera di singolo easy-to-access data store cosÃ¬ che sono pronti per le prossime fasi.
- **Clean**: I dati vengono mergiati, puliti e normalizzati utilizzando uno schema omogeneo e unificato.
- **Access**: I dati sono accessibili. Svariate view o access patterns sono forniti per semplificare e accelerare gli accessi al dataset che verrÃ  utilizzato per scopi di training.

## V dei Dati
#### Volume
>  Quanti dati ci sono?

Il continuo collezionare e analizzare big data sta diventando la sfida principale lungo l'IT. Le soluzioni si dividono in queste 2 categorie:
- **Scalable Storage**: si riferisce ad aggiungere piÃ¹ macchine e distribuirci il carico (reads, writes). Questo processo Ã¨ conosciuto come **scaling orizzontalmente**. Anche query e meccanismi di accesso che forniscono punti di accessi al dataset. PiÃ¹ macchine che eseguono tasks in parallelo.
- **Scalable Processing**: si riferisce ad un aggiunto di potenza di calcolo per eseguire calcoli su larga scala in modo veloce, parallelo e distribuito. Richiede un approccio distribuito alle interrogazioni, un protocollo per un efficiente comunicazione sulla rete, monitoring, e uno specifico paradigma per il processing distribuito.
![[Pasted image 20250617132841.png]]

I Grafi possono fornire supporto per risolvere problemi di Volume. Un Graph-based model permette di memorizzare dati da piÃ¹ sorgenti in un'unica source of truth che offre multipli e rapidi access patterns.
In una piattaforma big data, i grafi possono aiutare il problema di volume:
- **Main Data Source**: il grafo rappresenta l'**intera base dati** con il livello massimo di dettaglio. Un graph DB adeguato deve esporre:
	- Una *indexing structure* per supportare accessi random.
	- Un *access pattern* per accedere solo uno piccola porzione del grafo, eliminando la necessitÃ  di complessi lookup index o DB scanning.
- **Materialized Views**: il grafo rappresenta un subset del dataset principale o una versione aggregata dei dati (**versione sintetica**). Utile per le analisi, la visualizzazione, o la comunicazione dei risultati. 
#### Velocity
> Quanto frequente o a real-time sono i dati?

Il sistema deve essere non solo capace di processare dati velocemente, ma anche generare predizioni il piÃ¹ velocemente possibile.
Nel caso di una macchina a guida autonoma: deve essere veloce ad elaborare ed evitare i pedoni.
La velocitÃ  dei dati in entrata non Ã¨ l'unico problema: Ã¨ possibile risolvere il problema by streaming fast-moving data nel bulk storage per un successivo batch processing. 
L'importanza della velocitÃ  sta nella velocitÃ  totale del feedback loop che coinvolge data in input per decisioni.
![[Pasted image 20250402111542.png]]
#### Variety
> Quanti tipi di dati ci sono? (formato, struttura e grandezza)

La VarietÃ  indica i diversi tipi e la diversa natura dei dati che vengono analizzati. Raramente i dati sono perfettamente ordinati e pronti al processing poichÃ© derivano da diverse sorgenti. Tutte le piattaforme big data **devono essere flessibili per gestire queste varietÃ **, considerando inoltre l'evoluzione imprevedibile dei dati.
#### Veracity
> Quanto precisi e veritieri sono i dati?

Indicano la qualitÃ  e la veriditicitÃ  dei dati collezionati. 


> [!NOTE] Due Approcci
> Gli approcci per gestire queste sfide possono essere raggruppate in due categorie:
> - **Metodologiche**: include tutte le decisione design che coinvolgono l'architettura, gli algoritmi, lo storage schema e i cleaning methods.
> - **Tecnologiche**: include tutti i design di aspetti associati al DBMS da utilizzare, la configurazione cluster da adottare, e l'affidabilitÃ  delle soluzioni.

---
# Graphs for Big Data

#### Caso d'uso (Esempio)
Sei un poliziotto che deve rintracciare un criminale attraverso le torrette telefoniche. L'obiettivo Ã¨ monitorare i dati delle torrette per creare un modello predittivo e identificare le locazioni piÃ¹ rilevanti secondo il soggetto in osservazione.

Utilizzeremo grafi per organizzare i dati e creare graph-based materialized view dei movimenti del soggetto.
Il grafo risultante viene analizzato con un algoritmo che identifica clusters di posizioni. Queste posizioni vengono utilizzate dall'algoritmo successivo per costruire un modello predittivo.
![[Pasted image 20250402110352.png]]
**Approccio Generale**:
- Numerosi dati in forma di eventi (spostamento tra torrette).
- I dati sono distribuiti diverse sorgenti data (torrette).
- I dati necessitano di essere aggregati e organizzati in una forma che semplifica i processi e analisi future.
- Dalla prima aggregazione, abbiamo creato alcune views (foto precedente con clusters).
- Servono alcune real-time view per gli ultimi spostamenti per reagire velocemente.

**Problemi Architetturali**:
- Gli eventi di log delle torrette presentano dati grezzi (*raw*), immutabili e veri. 
- Diverse view create in funzione all'algoritmo di analisi.
- La view-building process opera generalmente su tutto il dataset, e questo puÃ² richiedere tempo in contesti grandi. Il tempo richiesto crea un gap tra i precedenti eventi che vengono elaborati e quelli attuali in real-time.
- Per avere real-time, c'Ã¨ bisogno di uno **streaming process** che legge gli eventi e accoda le informazioni.
---
## Architettura Lambda
![[Pasted image 20250402111621.png|500]]
I problemi architetturali possono essere indirizzati dall'Architettura Lambda, la quale concepisce il sistema big data come una serie di 3 livelli:
- **Batch Layer**: livello che elabora i dati in blocchi (batch) e fornisce analisi storiche complete.
- **Serving Layer**: livello che memorizza e serve i dati elaborati agli utenti per le queries.
- **Speed Layer**: livello che processa i dati in streaming per renderli disponibili quasi in tempo reale.
Ciascun livello soddisfa un subset dei requisiti e si basa sulla funzionalitÃ  fornita dagli altri strati.
L'Architettura Lambda contiene una tradizionale batch data pipeline e una pipeline fast streaming per dati real-time, ed un livello serving per queries.

> L'Architettura Lambda Ã¨ una tecnologia agnostica incentrata sul gestire enormi quantitÃ  di dati favorendo sia metodi di batch che di stream-processing. Cerca di bilanciare le preoccupazioni intorno a **latency**, **data consistency**, **scalability**, **fault tolerance** e **human fault tolerance** utilizzando batch processing per fornire comprensibili e accurate views di data, mentre si utilizza simultaneamente real-time stream processing.

- **Latency**: i dati grezzi vengono indicizzati nel livello di serving in modo che gli utenti finali possano interrogarli e analizzarli. PoichÃ© l'indicizzazione batch richiede tempo, c'Ã¨ un gap di tempo in cui i dati non sono ancora disponibili per l'analisi. Lo speed layer utilizza tecnologie di stream processing per indicizzare immediatamente i dati recenti, riducendo il periodo di indisponibilitÃ  e migliorando la latenza.
- **Data Consistency**: Lambda riduce il rischio di inconsistenza dei dati nei sistemi distribuiti, poichÃ© elabora i dati in modo sequenziale. Questo evita sovrapposizioni e garantisce che i dati riflettano sempre lo stato piÃ¹ recente sia nel batch che nello speed.
- **Scalability**: Lambda Ã¨ basata su tecnologie distribuite e scalabili, il che significa che Ã¨ possibile espandere la capacitÃ  aggiungendo nuovi nodi. Questo vale per tutte le fasi del processo: sorgente dati, batch, serving e speed layer.
- **Fault Tolerance**: essendo costruita su sistemi distribuiti, Lambda garantisce continuitÃ  anche in casi di guasti hardware. Se si verifica un errore nell'indicizzazione, Ã¨ possibile eseguire nuovamente il processo nel batch/serving layer mentre lo speed continua a elaborare i dati recenti.
- **Human Fault Tolerance**: i dati grezzi vengono sempre conservati, consentendo di ricreare gli indici in caso di bug o errori di omissione nel codice di indicizzazione. Se necessario, il codice puÃ² essere corretto e l'intero dataset puÃ² essere rielaborato per garantire dati sempre affidabili.
#### Querying
- Possiamo eseguire **query on the fly** (al volo) -> questo approccio Ã¨ generalmente impossibile a causa della quantitÃ  di dati da elaborare e la natura delle fonti di dati da accedere.
- Approccio alternativo Ã¨ **precomputare il risultato della query** o un valore intermedio per velocizzare i risultati della query finale.
Chiamiamo il query result, intermedio o finale, **batch view**.

![[Pasted image 20250402115322.png]]
Tutti i dati nel formato *raw* sono memorizzati nel **Batch Layer**. Questo livello Ã¨ responsabile per l'accesso ai dati raw e le batch view computation e extraction.
Le view risultanti vengono memorizzate nel **Serving Layer**, dove verranno indicizzate in maniera specifica e accedute durante le queries. 
Il serving layer viene aggiornato ogni volta che il batch layer finisce di precomputare una batch view.

![[Pasted image 20250402115745.png]]
Lo **Speed Layer** fornisce delle views degli ultimi dati, riducendo il gap tra il batch layer e gli ultimi dati arrivati. Questo livello guarda solo gli ultimi dati, mentre il batch layer guarda tutti i dati.
Questo permette di rispondere piÃ¹ velocemente agli ultimi cambiamenti facilitando e migliorando le analisi.

#### Indexing
I livelli batch e serving continuamente indicizzano i dati in entrata. 
I dati vengono indicizzati simultaneamente nel livello serving e speed.
Una volta indicizzati, i dati sono accessibili dalle query e quindi rimuovo questi dati dallo speed layer.
![[Pasted image 20250402120505.png]]

---
# Graphs for Master Data Management
I grafi possono essere utilizzati per creare delle views:
- **Batch Layer** -> rappresentazione periodica o aggregata dei dati.
- **Speed Layer** -> rappresentazione in real-time di una porzione dei dati.

I dati transazionali grezzi non risiedono nel grafo, ma rimangono nel **master dataset**. Questo Ã¨ utile quando Ã¨ sufficiente lavorare su **dati aggregati** e si accede a questi dati tramite il **Serving Layer**.
#### Limite
Alcuni tipi di analisi **non possono essere eseguiti sui dati aggregati** perchÃ©:
- Richiedono **dettagli precisi**.
- Gli algoritmi coinvolti hanno bisogno di **dati completi** e non riassunti.
In questi casi, **il grafo puÃ² ancora essere utilizzato** ma come strumento per la rappresentazione dei **collegamenti** e l'estrazione di **insights**. 
Derivare significati dai collegamenti fornisce una potenza analitica che i metodi non a grafo non offrono, rendendo il grafo:
- La principale fonte di conoscenza.
- Fonte unificata e connessa della veritÃ .

### Caso d'uso: Transazione Fraudolente
![[Pasted image 20250617141028.png|450]]
**Partendo da questo dataset transazionale, definiamo un modello a grafo:**
- Ogni transazione coinvolge due nodi: una **persona** (il cliente o lâ€™utente) e un **commerciante**.
- I nodi sono **collegati dalle transazioni stesse**.
- Ogni transazione ha una **data** e uno **stato**:
    - _undisputed_ per le transazioni **legittime**,
    - _disputed_ per quelle **segnalate come fraudolente**.

**Ricerca della sorgente del furto. Partendo dal grafo, gli step sono:
- *Filtrare le transazioni fraudolenti*. Identificare le persone e le carte coinvolte.
- *Identificare il punto di origine del furto*. Ricerca di tutte le transazioni avvenute prima della frode.
- *Isolare i ladri*. Identificare qualche pattern comune, come un mercante in comune che potrebbe essere l'origine dei furti.
In questo caso si nota come tutti e 3 gli utenti hanno in comune il Burger King.
![[Pasted image 20250617141944.png|300]]
## Vantaggi dei Grafi:
- **Molteplici fonti di dati**, come informazioni geografiche o GPS, dati dei social network, profili personali degli utenti, dati familiari e simili, possono essere **unificate in un'unica sorgente di veritÃ  connessa**.
- I dati esistenti possono essere **arricchiti con fonti esterne di conoscenza** (es. posizione dei negozi, indirizzi delle persone, ecc.) o con **informazioni contestuali** (es. un nuovo negozio, altre segnalazioni), utili per **migliorare lâ€™analisi**.
- **Lo stesso modello di dati puÃ² supportare diverse tecniche di analisi** (ad esempio per scoprire unâ€™organizzazione fraudolenta, ovvero â€œun'organizzazione che si dedica a truffare le persone. Falsificazioni, false dichiarazioni, furto dâ€™identitÃ , contraffazione di assegni e valute sono tutte attivitÃ  fraudolente.â€).
- I dati possono essere **visualizzati come un grafo** per **accelerare lâ€™analisi manuale**. Lâ€™analisi puÃ² essere **estesa a piÃ¹ livelli di interazione**, considerando **piÃ¹ salti (hops)** tra i nodi.
- La struttura del grafo **semplifica le operazioni di fusione e pulizia** dei dati, grazie ai **pattern di accesso flessibili** forniti dal modello a grafo.

## Grafi come Master Data Management (MDM)
- Il grafo rappresenta **la principale fonte di conoscenza** per i dati **fusi, puliti ed estesi**, su cui viene eseguita lâ€™analisi e **su cui si basano le decisioni**.
- Il grafo svolge il **ruolo di dataset principale** ed Ã¨ la **fondazione per il Master Data Management (MDM)** â€” la pratica di **identificare, pulire, memorizzare e governare i dati**
#### Principali preoccupazioni del MDM
- Gestire i **cambiamenti nel tempo**, man mano che le **strutture organizzative cambiano**, le aziende si fondono e **le regole aziendali evolvono**
- **Incorporare nuove fonti di dati**
- **Arricchire i dati esistenti** con **fonti esterne**
- Soddisfare le esigenze di **reporting, conformitÃ  e business intelligence**
- **Versionare i dati** quando cambiano i **valori o lo schema**
### MDM vs Data Warehouse
- L'MDM **non Ã¨ unâ€™alternativa nÃ© una versione moderna del Data Warehouse (DW)**, anche se **le due pratiche hanno molto in comune**.
- Il Data Warehouse riguarda la **memorizzazione di dati storici**, mentre l'MDM si occupa dei **dati attuali**.
- Una soluzione MDM contiene **le informazioni correnti e complete** di **tutte le entitÃ  aziendali** allâ€™interno di unâ€™organizzazione.
![[Pasted image 20250617142733.png|430]]
#### 1) Obiettivi differenti
- **DW**: analizzare i dati in modo multidimensionale
- **MDM**: creare e mantenere **unâ€™unica fonte di veritÃ ** per una particolare dimensione dellâ€™organizzazione
#### 2) Tipi di dati differenti
- **DW** include **sia dati transazionali che non transazionali**
- **MDM** si applica alle **entitÃ ** e **non ai dati transazionali**
- **MDM** riguarda solo i dati contenuti in **tabelle dimensionali**, **non nella Fact Table**
#### 3) Esigenze di reporting differenti
- **DW**: fornire agli utenti finali **report analitici** adeguati
- **MDM**: Ã¨ molto piÃ¹ importante fornire report su **governance dei dati, qualitÃ  dei dati e conformitÃ **, piuttosto che report per fini analitici
#### 4) Dove vengono utilizzati i dati
- In un **DW**, le applicazioni accedono **direttamente al data warehouse**; le fonti originali dei dati **non vengono modificate**
- In **MDM**, spesso Ã¨ necessario avere una **strategia per reinserire i dati master nelle fonti originarie**, il che pone delle sfide non presenti nei DW:
    - **Come/su quale frequenza sincronizzare** i dati con la fonte originale?
    - **Come gestire le modifiche** ai dati durante il processo di pulizia?

> [!NOTE] MDM vs DW 
> - **MDM** = qualitÃ , coerenza e controllo dei dati di riferimento attuali.
> - **DW** = consolidamento e analisi dei dati storici e transazionali.
> Entrambi sono complementari, un MDM ben fatto migliora la qualitÃ  dei dati che poi alimentano il DW.
### Vantaggi del MDM
Il Master Data Management offre numerosi benefici:
- **Ottimizzazione della condivisione dei dati** tra personale e dipartimenti
- **Facilitazione dellâ€™elaborazione** su architetture, piattaforme e applicazioni diverse
- **Eliminazione di incoerenze e duplicati** nei dati
- **Riduzione della frustrazione** nella ricerca di informazioni
- **Semplificazione delle procedure aziendali**
- **Miglioramento della comunicazione** allâ€™interno dellâ€™organizzazione
### Vantaggi del MDM basato su grafo
Il Master Data Management basato su grafo presenta i seguenti vantaggi:
- **FlessibilitÃ ** â€” I dati catturati possono essere **facilmente modificati** per includere **nuovi attributi e oggetti**
- **EstendibilitÃ ** â€” Il modello permette una **rapida evoluzione** in linea con i cambiamenti del business
- **CapacitÃ  di ricerca** â€” Ogni **nodo**, ogni **relazione** e **le relative proprietÃ ** rappresentano **punti di accesso alla ricerca**
- **CapacitÃ  di indicizzazione** â€” I database a grafo sono **naturalmente indicizzati** sia per **nodi** che per **relazioni**, permettendo **accessi piÃ¹ rapidi** rispetto ai database relazionali

---
# Graphs Data Management
Utilizzare grafi in ML projects richiede memorizzazione, accesso, query e gestione di ciascuno di questi grafi: questo Ã¨ chiamato **Graph Data Management**.
- **Modeling**: 
	- Lo stesso aspetto della realtÃ  puÃ² essere mappato in molteplici modi in un graph model.
	- "Schemaless" natura dei grafi.
	- Il design del modello influenza le performance di tutte le queries e analisi.
- **Storage**:
	- Persistent data storage, memory use, caching, query languages, data integrity e consistency.
	- In aggiunta: scalabilitÃ , affidabilitÃ  e performance.
- **Processing**:
	- Frameworks (tools, linguaggi query e algoritmi) per processare e analizzare grafi.
	- Di solito, utilizzare piÃ¹ macchine migliora le performance.
	- Alcune features di processo, come linguaggio di query, sono accessibili nel DBMS stesso.

Aspetti tecnologici associati alla gestione di grafi sono importanti in progetti *machine learning*, nei quali Ã¨ necessario manipolare, memorizzare e accedere dati reali.
In molti casi, Ã¨ necessario lavorare con grandi moli di dati, **problemi legati alla scalabilitÃ ** sono cruciali:
- **Sharding**: suddividere i dati orizzontalmente tra i diversi servers.
- **Replication**: duplicare i dati su diversi server, per una maggiore accessibilitÃ  e per scopi di scalabilitÃ .
- **Native** **vs non native graph databases**: problemi di performance durante lo storage/querying.
- **Label property graphs**.

## Sharding
Guardando applicazioni con grandi quantitÃ  di dati da un punto di vista puramente della memoria, le principali sfide sono:
- **Volume**: il volume dei dati coinvolti Ã¨ cosÃ¬ grande da non riuscire a memorizzare tutto su una singola macchina.
- **Velocity**: una singola macchina puÃ² servire solo un numero limitato di users allo stesso momento.

**Sharding**: un grande dataset viene suddiviso, e i subset sono distribuiti lungo diversi server.
**Sharding** **strategy**: determina quale partizione dei dati dovrebbe essere inviata a quale frammento (server).
![[Pasted image 20250408132232.png]]

L'**attraversamento delle relazioni in mezzo a due shards** sono molto costose computazionalmente e in termini di performance.
![[Pasted image 20250408154649.png|400]]
**Overloading un singolo shard**: nodi associati sono memorizzati sullo stesso shard permettendo un attraversamento piÃ¹ rapido, ma il carico sugli shard Ã¨ altamente sbilanciato. Questo puÃ² provocare tempi di accesso imprevedibili, rendendo questa soluzione inconveniente da implementare.
![[Pasted image 20250408160101.png|400]]

### Sharding Techniques
- **Application Level Sharding**:
	- Lo Sharding dei dati Ã¨ compiuto lato applicativo utilizzando le conoscenze del dominio specifico (per esempio suddividere i dati in base alla geo-localizzazione degli utenti).
	- Lo Sharding si puÃ² basare su diverse tipologie di analisi o processi che il grafo deve eseguire sui dati.
	- Ciascuno Shard contiene tutti i dati richiesti per eseguire l'algoritmo, e alcuni nodi possono essere replicati tra gli Shards.
![[Pasted image 20250408161112.png|500]]
- **Aumentare la RAM o utilizzare Cache Sharding**: 
	- E' possibile scalare il server verticalmente, aggiungendo piÃ¹ RAM cosÃ¬ che tutto il DB stia in memoria.
	- Questa soluzione rende l'attraversamento del grafo estremamente veloce ma Ã¨ strettamente impossibili per enormi DB.
	- **Cache Sharding**: mantiene prestazioni elevate con set di dati che superano di gran lunga la capacitÃ  di memoria. Non memorizza l'intero dataset in ciascuna istanza DB.
	- Per implementare la condivisione della cache, partizioniamo il carico di lavoro di ciascuna istanza del DB, per aumentare la probabilitÃ  di raggiungere una cache calda per una determinata richiesta.
- **Replication** (di seguito)

## Replication
E' possibile ottenere una maggiore scalabilitÃ  del DB aggiungendo piÃ¹ copie identiche (in piÃ¹ server) del DB che agiscono come followers con accessi read-only.
La Data Replication consiste nel mantenere copie multiple, definite replicas, su computer separati. La Replication ha diversi scopi:
- **System Availability**: la replicazione rimuove single points of failure permettendo l'accessibilitÃ  di data items da multipli siti. Anche quando dei cluster vanno down, i dati dovrebbero comunque rimanere accessibili.
- **Performance**: la replicazione riduce la latenza allocando i dati piÃ¹ vicini agli access points.
- **Scalability**: la replicazione permette ai sistemi di crescere, sia geograficamente che in termini di numero di richieste di accesso, mantenendo tempi di risposta accettabili.
- **Application Requirements**: come parte di specifiche operazionali, applicazioni possono richiedere multiple copie di dati da mantenere.
#### Sincronizzazione
**Mantenere le diverse copie sincronizzate** Ã¨ una challenge. Una decisione fondamentale nel design del protocollo di replicazione Ã¨ dove gli aggiornamenti del DB sono inizialmente eseguiti. Le tecniche possono essere caratterizzate come segue:
- **Centralizzato** -> se il primo aggiornamento avviene su una master copy. 
- **Distribuito** -> se Ã¨ permesso l'update di qualunque replica.
![[Pasted image 20250408130916.png]]
*Un **nodo master** Ã¨ tipicamente responsabile del processo di aggiornamento dei dati. Anche quando una replica permette la scrittura, queste operazioni devono passare da un master per essere eseguite.*

#### Casi d'uso:
- Nell'esempio delle torrette cellulari: un grafo viene creato per monitorare ciascun soggetto, cosÃ¬ la ML model produce multipli grafi indipendenti che vengono accessi in modo isolato. In questo caso l'application level sharding Ã¨ un task semplice perchÃ© i grafi sono isolati. Generalizzando, nello scenario graph based Lambda Architecture, con multiple graph views create sullo stesso dataset, possiamo memorizzare le views in istanze multiple di database perchÃ¨ sono accesso in maniera indipendente.
- Nella fraud detection: l'operazione di sharding sarÃ  complicata perchÃ© in teoria tutti i nodi possono essere connessi. Possono essere applicate delle euristiche per ridurre il cross-shard traversal o per mantenere i nodi che sono frequentemente acceduti insieme nella stessa shard, ma il grafo non puÃ² essere diviso in diversi grafi isolati come nel caso precedente. **In questi casi un'altra opzione Ã¨ quella di replicare (duplicare) per scalare le performance in lettura e la velocitÃ  dei tempi di analisi.**

## Native Graph Databases
Ci sono numerose modalitÃ  per rappresentare grafi nei differenti database engines.
Un DBMS costruito per **gestire flussi di lavoro di grafi per tutto il computing stack**, dalla lingua query al database management engine e filesystem e dal clustering al backup e il monitoring, Ã¨ chiamato **Native Graph Database**.
Native Graph DB sono progettati per l'uso del filesystem in un modo che non si occupa solo di comprendere, ma anche di supportare grafi, significando che sono sia **altamente performanti** che **sicuri** per carichi di lavoro dei grafi.
In particolare, un Native Graph DBMS presenta una proprietÃ  chiamata "**index-free adjacency**", la quale mantiene per ciascun nodo **riferimenti diretti ai suoi nodi adiacenti**.
> La lista di adiacenza rappresenta il metodo piÃ¹ comune per rappresentare *grafi sparsi*.

![[Pasted image 20250417175420.png]]
**Memoria richiesta**: V + E
## Non-native Graph Databases
I Non-native Graph DB possono essere suddivisi in 2 categorie:
- Quelli che sovrappongono un **graph API in cima ad una struttura dati diversa esistente**, come chiave/valore, relazionale, documenti, o store column-based.
- Quelli che sostengono la semantica multimodello, in cui **un sistema puÃ² supportare diversi modelli di dati**.
Un Non-Native Graph Engine Ã¨ ottimizzato per un modello storage alternativo (relazionale, column based..), cosÃ¬ quando si ha a che fare con i grafi, il DBMS deve eseguire costose traduzioni da e verso il modello primario del DB.
Gli sviluppatori possono provare ad ottimizzare queste "traduzioni" attraverso denormalizzazioni radicali, ma questo approccio tipicamente porta ad alta latenza quando si interroga il grafo.
> In altre parole, un Non-Native Graph DB non sarÃ  mai performante come un Native Graph DB, per il semplice fatto che Ã¨ sempre richiesta una traduzione.
## Vantaggi di un'Architettura Native Graph
-  **Da minuti a millisecondi**: I Native Graph DB gestiscono connected data queries **molto piÃ¹ velocemente** dei Non-native Graph DB. Anche in hardware modesti, i Native possono facilmente gestire milioni di attraversamento per secondo, e piÃ¹ di migliaia di scritture di attraversamenti per secondo.
- **Efficienza di lettura**: I Native Graph DB possono consegnare attraversamenti con tempi costanti con l'index-free adjacency senza alcun bisogno di progettare schemi complessi e ottimizzazioni delle query. Evita di creare qualunque logica applicativa complicata per il processing delle connessioni.
- **Ottimizzazione dello spazio**: Per migliorare le performance di un Non-native Graph DB, Ã¨ possibile denormalizzare gli indici o crearne di nuovi, influendo sulla quantitÃ  di spazio necessaria per memorizzare la stessa quantitÃ  di informazioni.
- **Efficienza di scrittura**: La denormalizzazione influisce anche sulle performance di scrittura perchÃ© tutte queste strutture di indici necessitano di essere aggiornate anche loro.
## Requisiti Machine Learning
In un progetto ML di successo, ogni singolo aspetto Ã¨ rilevante per consegnare un servizio efficiente e performante agli utenti finali, dove efficiente e performante non significa solo accurato, ma anche consegnato in tempo.
#### Esempio caso d'uso
Devi implementare una sistema manageriale per una supply chain che analizza l'intera catena per predire problemi di stack inventory nel futuro o individuare "colli di bottiglia" nella rete.
Comprende la pianificazione e la gestione di tutte le attivitÃ  coinvolte nell'approvvigionamento, nella conversione e in tutte le attivitÃ  di gestione logistica.
![[Pasted image 20250417182523.png|400]]
![[Pasted image 20250417182602.png]]
Questi indici aggiungono un livello di indirezione ad ogni attraversamento, comportando cosÃ¬ un costo computazionale maggiore.
Per trovare dove "Finished Product B" sarÃ  consegnato, dobbiamo prima eseguire un lookup index (costo O(log n)) e poi ottenere la lista dei prossimi nodi nella catena.
Questo approccio potrebbe essere accettabile per lookups occasionali o poco profondi, e velocemente diventa insostenibile in termini computazionali quando invertiamo le direzioni degli attraversamenti.

**IDEA**: **Utilizzare un modello a Grafo** per memorizzare la supply chain.
Supponiamo che il "Raw Product A" Ã¨ contaminato o non disponibile, e dobbiamo trovare tutti i prodotti o negozi affetti da questo problema nella catena.
Dovremmo eseguire lookup multipli, uno per ciascun nodo nella catena tra il "raw product" e i negozi, rendendo il costo insostenibile (costo O(m log n), dove m sono i salti).
In un Native Graph DB con index-free adjacency, con collegamenti bidirezionali precomputati e memorizzati come relazioni, il costo dello stesso attraversamento precedente Ã¨ di O(m). Non solo il Graph Engine Ã¨ piÃ¹ veloce, ma inoltre il costo Ã¨ correlato solo al numero di salti (m), non al numero totale di relazioni (n).
![[Pasted image 20250417184000.png]]

### Come identificare un "collo di bottiglia"
Un metodo comune di identificare un collo di bottiglia in una rete Ã¨ la **Betweenness Centrality**, la quale Ã¨ una misura di centralitÃ /importanza che si basa sul calcolare i cammini minimi tra i nodi.
- Si tratta del numero di Shortest Path che passano su ciascun nodo.
---
## Label Property Graph
Graph DBMS providers hanno introdotto il modello Label Property Graph per collegare un **set di attributi** a nodi e relazioni e aggiungere classi o **tipi di nodi e relazioni**.
Questo modello permette un piÃ¹ complesso set di query features tipico di tutti i DBMS, come *projection*, *filtering*, *grouping* e *counting*.

#### Definizione
> Secondo openCypher, un Label Property Graph Ã¨ definito come "*un multigrafo diretto, con vertici e nodi etichettati con self-edges, dove gli archi hanno una propria identitÃ *".

Una label Ã¨ una stringa di testo che identifica un tipo, un set o una categoria di dati o oggetti.
Un oggetto etichettato (labeled):
- Ã¨ opzionale e non deve per forza essere unico.
- Ã¨ simile ad un tag che indica un raggruppamento o una categoria.
- puÃ² avere piÃ¹ etichette.
![[Pasted image 20250417190621.png]]

#### ProprietÃ 
- Il **Grafo** consiste di un *set di entitÃ *. Un'entitÃ  rappresenta o un *nodo* o una *relazione*.
- Ciascuna **entitÃ ** ha un *identificatore* che la identifica univocamente per tutto il grafo.
- Ciascuna **relazione** ha una *direzione*, un *nome* che identifica il tipo, un nodo di inizio e un nodo di fine.
- Un'**entitÃ ** puÃ² avere un *set di proprietÃ *.
- I **nodi** possono essere taggati con una o *piÃ¹ labels*.
![[Pasted image 20250417191102.png]]
---
---
----
---
---
### ğŸ” **Ciclo di Vita dei Dati**

- **Collect**: raccogliere dati da piÃ¹ sorgenti.
    
- **Store**: salvare i dati in modo accessibile e centralizzato.
    
- **Clean**: unificare e normalizzare i dati.
    
- **Access**: accedere ai dati con pattern rapidi ed efficienti.
    

---

## ğŸ“ **Le 4 V dei Big Data**

- **Volume**: quantitÃ  di dati â†’ richiede **scalabilitÃ ** (storage e processing).
    
- **Velocity**: velocitÃ  di acquisizione e risposta â†’ serve **real-time processing**.
    
- **Variety**: diversitÃ  di formato e struttura â†’ richiede **flessibilitÃ  della piattaforma**.
    
- **Veracity**: qualitÃ  e affidabilitÃ  dei dati â†’ richiede **pulizia e validazione**.
    

---

## ğŸ§  **Graphs & Big Data**

- **Graph Model**: unifica sorgenti diverse in un'unica struttura connessa.
    
- **Main Data Source**: grafo con tutti i dati grezzi e dettagliati.
    
- **Materialized View**: sottinsiemi aggregati per analisi o visualizzazione.
    

---

## âš™ï¸ **Architettura Lambda**
Architettura utilizzata per la progettazione di sistemi **big data** e **machine learning**

- **Batch Layer**: elabora dati storici in batch.
    
- **Serving Layer**: serve i risultati precomputati.
    
- **Speed Layer**: gestisce lo streaming in tempo reale.
    

âœ³ï¸Â **Obiettivi**:

- Bassa **latenza**, alta **consistenza**, buona **scalabilitÃ **, **tolleranza ai guasti** (inclusi quelli umani).
    

---

## ğŸ” **Query & Indexing**

- **Batch View**: risultato precomputato per query piÃ¹ rapide.
    
- **Speed Layer**: colma il gap tra dati recenti e batch.
    
- **Indicizzazione**: necessaria per rendere i dati interrogabili velocemente.
    

---

## ğŸ›¡ï¸ **MDM (Master Data Management)**

- **Fonte unica e aggiornata** per entitÃ  aziendali.
    
- Gestisce: evoluzione, qualitÃ , arricchimento, versioning dei dati.
    
- âœ… **Vantaggi**: coerenza, condivisione, semplificazione, riduzione errori.
    

### ğŸ†š **MDM vs Data Warehouse**

|               | MDM                         | Data Warehouse            |
| ------------- | --------------------------- | ------------------------- |
| **Tipo dati** | Attuali, dimensionali       | Storici, transazionali    |
| **Obiettivo** | Fonte unica di veritÃ        | Analisi multidimensionale |
| **Reporting** | Governance, qualitÃ          | Business intelligence     |
| **Utilizzo**  | Modifica & sincronizzazione | Solo lettura              |

---

## ğŸ”— **Graphs in MDM**

- **Grafo = fonte centrale di conoscenza**
    
- Utile per analisi avanzate (es. frodi) grazie ai collegamenti.
    
- Supporta diversi livelli di granularitÃ  (raw e aggregati).
    

---

## ğŸ§° **Graph Data Management**

- **Modeling**: modellare la realtÃ  nel grafo, senza schema fisso.
    
- **Storage**: salvataggio persistente, caching, consistenza.
    
- **Processing**: linguaggi e algoritmi per analisi grafo.
    

---

## ğŸ§© **ScalabilitÃ  nei Graph DB**

### âœ‚ï¸ **Sharding**

- **Orizzontale**: divide il dataset tra server.
    
- Sfide: traversamenti cross-shard â†’ costosi.
    

### ğŸ” **Replication**

- Copie multiple per aumentare **affidabilitÃ ** e **prestazioni di lettura**.
    
- **Centralizzata** (master) o **distribuita** (multi-scrittura).
    

---

## âš™ï¸ **Tecnologie Scalabili**

- **Application-Level Sharding**: sharding basato sulla logica del dominio.
    
- **Cache Sharding**: suddivisione del carico su piÃ¹ cache per prestazioni.
    
- **RAM Scaling**: aumentare memoria locale â†’ limitato nei big data.
    

---

## ğŸš€ **Native vs Non-Native Graph DB**

|Caratteristica|Native Graph DB|Non-Native Graph DB|
|---|---|---|
|Storage|Ottimizzato per grafi|Traduzione da modelli non a grafo|
|Performance traversamenti|Altissima (O(m))|Bassa (O(m log n))|
|Architettura|Index-free adjacency|Lookup + indici esterni|
âœ… **Native = piÃ¹ veloce, efficiente, scalabile**.

---

## ğŸ” **Label Property Graph**

- **Nodi e relazioni con etichette e proprietÃ **.
    
- Supporta: **filtering**, **projection**, **grouping**, **counting**.
    
- Definizione openCypher: **multigrafo diretto etichettato**.
    

---

## ğŸ›’ **Use Case: Supply Chain + Fraud Detection**

- **Supply Chain**: analisi flusso materiali â†’ trova colli di bottiglia.
    
- **Betweenness Centrality**: misura per individuare i nodi critici.
    
- **Fraud Graph**: traccia transazioni fraudolente, individua pattern sospetti.