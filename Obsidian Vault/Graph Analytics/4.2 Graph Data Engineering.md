## Life Cycle dei Big Data
- **Collect**: Data da svariate sorgenti sono raggruppate e collezionate.
- **Store**: I dati sono memorizzati in maniera di singolo easy-to-access data store così che sono pronti per le prossime fasi.
- **Clean**: I dati vengono mergiati, puliti e normalizzati utilizzando uno schema omogeneo e unificato.
- **Access**: I dati sono accessibili. Svariate view o access patterns sono forniti per semplificare e accelerare gli accessi al dataset che verrà utilizzato per scopi di training.

## V dei Dati
#### Volume
>  Quanti dati ci sono?

Il continuo collezionare e analizzare big data sta diventando la sfida principale lungo l'IT. Le soluzioni si dividono in queste 2 categorie:
- **Scalable Storage**: si riferisce ad aggiungere più macchine e distribuirci il carico (reads, writes). Questo processo è conosciuto come **scaling orizzontalmente**. Anche query e meccanismi di accesso che forniscono punti di accessi al dataset. Più macchine che eseguono tasks in parallelo.
- **Scalable Processing**: richiede un approccio distribuito alle interrogazioni, un protocollo per un efficiente comunicazione sulla rete, monitoring, e uno specifico paradigma per il processing distribuito.
I Grafi possono fornire supporto per risolvere problemi di Volume. Un Graph-based model permette di memorizzare dati da più sorgenti in un'unica source of truth che offre multipli e rapidi access patterns.
In una piattaforma big data, i grafi possono aiutare il problema di volume:
- **Main Data Source**: il grafo contiene tutti i dati on la minore granularità. Un graph DB adeguato deve esporre:
	- Una *indexing structure* per supportare accessi random.
	- Un *access pattern* per accedere solo uno piccola porzione del grafo, eliminando la necessità di complessi lookup index o DB scanning.
- **Materialized Views**: il grafo rappresenta un subset del dataset principale o una versione aggregata dei dati, utile per le analisi, la visualizzazione, o la comunicazione dei risultati. 
#### Velocity
> Quanto frequente o a real-time sono i dati?

Il sistema deve essere non solo capace di processare dati velocemente, ma anche generare predizioni il più velocemente possibile.
Nel caso di una macchina a guida autonoma: deve essere veloce ad elaborare ed evitare i pedoni.
La velocità dei dati in entrata non è l'unico problema: è possibile risolvere il problema by streaming fast-moving data nel bulk storage per un successivo batch processing. 
L'importanza della velocità sta nella velocità totale del feedback loop che coinvolge data in input per decisioni.
![[Pasted image 20250402111542.png]]
#### Variety
> Quanti tipi di dati ci sono? (formato, struttura e grandezza)

La Varietà indica i diversi tipi e la diversa natura dei dati che vengono analizzati. Raramente i dati sono perfettamente ordinati e pronti al processing poiché derivano da diverse sorgenti. Tutte le piattaforme big data devono essere flessibili per gestire queste varietà, considerando inoltre l'evoluzione imprevedibile dei dati.
#### Veracity
> Quanto precisi e veritieri sono i dati?

Indicano la qualità e la veriditicità dei dati collezionati. 


> [!NOTE] Due Approcci
> Gli approcci per gestire queste sfide possono essere raggruppate in due categorie:
> - **Metodologiche**: include tutte le decisione design che coinvolgono l'architettura, gli algoritmi, lo storage schema e i cleaning methods.
> - **Tecnologiche**: include tutti i design di aspetti associati al DBMS da utilizzare, la configurazione cluster da adottare, e l'affidabilità delle soluzioni.

---
# Graphs for Big Data

#### Caso d'uso (Esempio)
Sei un poliziotto che deve rintracciare un criminale attraverso le torrette telefoniche. L'obiettivo è monitorare i dati delle torrette per creare un modello predittivo e identificare le locazioni più rilevanti secondo il soggetto in osservazione.

Utilizzeremo grafi per organizzare i dati e creare graph-based materialized view dei movimenti del soggetto.
Il grafo risultante viene analizzato con un algoritmo che identifica clusters di posizioni. Queste posizioni vengono utilizzate dall'algoritmo successivo per costruire un modello predittivo.
![[Pasted image 20250402110352.png]]
**Approccio Generale**:
- Numerosi dati in forma di eventi (spostamento tra torrette).
- I dati sono distribuiti diverse sorgenti data (torrette).
- I dati necessitano di essere aggregati e organizzati in una forma che semplifica i processi e analisi future.
- Dalla prima aggregazione, abbiamo creato alcune views (foto precedente con clusters).
- Servono alcune real-time view per gli ultimi spostamenti per reagire velocemente.

**Problemi Architetturali**:
- Gli eventi di log delle torrette presentano dati grezzi (*raw*), immutabili e veri. 
- Diverse view create in funzione all'algoritmo di analisi.
- La view-building process opera generalmente su tutto il dataset, e questo può richiedere tempo in contesti grandi. Il tempo richiesto crea un gap tra i precedenti eventi che vengono elaborati e quelli attuali in real-time.
- Per avere real-time, c'è bisogno di uno **streaming process** che legge gli eventi e accoda le informazioni.
---
## Architettura Lambda
![[Pasted image 20250402111621.png|500]]
I problemi architetturali possono essere indirizzati dall'Architettura Lambda, la quale concepisce il sistema big data come una serie di 3 livelli:
- **Batch Layer**: strato che elabora i dati in blocchi (batch) e fornisce analisi storiche complete.
- **Serving Layer**: strato che memorizza e serve i dati elaborati agli utenti per le queries.
- **Speed Layer**: strato che processa i dati in streaming per renderli disponibili quasi in tempo reale.
Ciascun livello soddisfa un subset dei requisiti e si basa sulla funzionalità fornita dagli altri strati.
L'Architettura Lambda contiene una tradizionale batch data pipeline e una pipeline fast streaming per dati real-time, ed un livello serving per queries.

> L'Architettura Lambda è una tecnologia agnostica incentrata sul gestire enormi quantità di dati favorendo sia metodi di batch che di stream-processing. Cerca di bilanciare le preoccupazioni intorno a **latency**, **data consistency**, **scalability**, **fault tolerance** e **human fault tolerance** utilizzando batch processing per fornire comprensibili e accurate views di data, mentre si utilizza simultaneamente real-time stream processing.

- **Latency**: i dati grezzi vengono indicizzati nel livello di serving in modo che gli utenti finali possano interrogarli e analizzarli. Poiché l'indicizzazione batch richiede tempo, c'è un gap di tempo in cui i dati non sono ancora disponibili per l'analisi. Lo speed layer utilizza tecnologie di stream processing per indicizzare immediatamente i dati recenti, riducendo il periodo di indisponibilità e migliorando la latenza.
- **Data Consistency**: Lambda riduce il rischio di inconsistenza dei dati nei sistemi distribuiti, poiché elabora i dati in modo sequenziale. Questo evita sovrapposizioni e garantisce che i dati riflettano sempre lo stato più recente sia nel batch che nello speed.
- **Scalability**: Lambda è basata su tecnologie distribuite e scalabili, il che significa che è possibile espandere la capacità aggiungendo nuovi nodi. Questo vale per tutte le fasi del processo: sorgente dati, batch, serving e speed layer.
- **Fault Tolerance**: essendo costruita su sistemi distribuiti, Lambda garantisce continuità anche in casi di guasti hw. Se si verifica un errore nell'indicizzazione, è possibile eseguire nuovamente il processo nel batch/serving layer mentre lo speed continua a elaborare i dati recenti.
- **Human Fault Tolerance**: i dati grezzi vengono sempre conservati, consentendo di ricreare gli indici in caso di bug o errori di omissione nel codice di indicizzazione. Se necessario, il codice può essere corretto e l'intero dataset può essere rielaborato per garantire dati sempre affidabili.
#### Querying
- Possiamo eseguire **query on the fly** (al volo) -> questo approccio è generalmente impossibile a causa della quantità di dati da elaborare e la natura delle fonti di dati da accedere.
- Approccio alternativo è **precomputare il risultato della query** o un valore intermedio per velocizzare i risultati della query finale.
Chiamiamo il query result, intermedio o finale, **batch view**.

![[Pasted image 20250402115322.png]]
Tutti i dati nel formato *raw* sono memorizzati nel **Batch Layer**. Questo livello è responsabile per l'accesso ai dati raw e le batch view computation e extraction.
Le view risultanti vengono memorizzate nel **Serving Layer**, dove verranno indicizzate in maniera specifica e accedute durante le queries. 
Il serving layer viene aggiornato ogni volta che il batch layer finisce di precomputare una batch view.

![[Pasted image 20250402115745.png]]
Lo **Speed Layer** fornisce delle views degli ultimi dati, riducendo il gap tra il batch layer e gli ultimi dati arrivati. Questo livello guarda solo gli ultimi dati, mentre il batch layer guarda tutti i dati.
Questo permette di rispondere più velocemente agli ultimi cambiamenti facilitando e migliorando le analisi.

#### Indexing
I livelli batch e serving continuamente indicizza i dati in entrata. 
I dati vengono indicizzati simultaneamente nel livello serving e speed.
Una volta indicizzati, i dati sono accessibili dalle query e quindi rimuovo questi dati dallo speed layer.
![[Pasted image 20250402120505.png]]