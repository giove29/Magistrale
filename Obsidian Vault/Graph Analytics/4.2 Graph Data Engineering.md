## Life Cycle dei Big Data
- **Collect**: Data da svariate sorgenti sono raggruppate e collezionate.
- **Store**: I dati sono memorizzati in maniera di singolo easy-to-access data store così che sono pronti per le prossime fasi.
- **Clean**: I dati vengono mergiati, puliti e normalizzati utilizzando uno schema omogeneo e unificato.
- **Access**: I dati sono accessibili. Svariate view o access patterns sono forniti per semplificare e accelerare gli accessi al dataset che verrà utilizzato per scopi di training.

## V dei Dati
#### Volume
>  Quanti dati ci sono?

Il continuo collezionare e analizzare big data sta diventando la sfida principale lungo l'IT. Le soluzioni si dividono in queste 2 categorie:
- **Scalable Storage**: si riferisce ad aggiungere più macchine e distribuirci il carico (reads, writes). Questo processo è conosciuto come **scaling orizzontalmente**. Anche query e meccanismi di accesso che forniscono punti di accessi al dataset. Più macchine che eseguono tasks in parallelo.
- **Scalable Processing**: richiede un approccio distribuito alle interrogazioni, un protocollo per un efficiente comunicazione sulla rete, monitoring, e uno specifico paradigma per il processing distribuito.
I Grafi possono fornire supporto per risolvere problemi di Volume. Un Graph-based model permette di memorizzare dati da più sorgenti in un'unica source of truth che offre multipli e rapidi access patterns.
In una piattaforma big data, i grafi possono aiutare il problema di volume:
- **Main Data Source**: il grafo contiene tutti i dati on la minore granularità. Un graph DB adeguato deve esporre:
	- Una *indexing structure* per supportare accessi random.
	- Un *access pattern* per accedere solo uno piccola porzione del grafo, eliminando la necessità di complessi lookup index o DB scanning.
- **Materialized Views**: il grafo rappresenta un subset del dataset principale o una versione aggregata dei dati, utile per le analisi, la visualizzazione, o la comunicazione dei risultati. 
#### Velocity
> Quanto frequente o a real-time sono i dati?

Il sistema deve essere non solo capace di processare dati velocemente, ma anche generare predizioni il più velocemente possibile.
Nel caso di una macchina a guida autonoma: deve essere veloce ad elaborare ed evitare i pedoni.
La velocità dei dati in entrata non è l'unico problema: è possibile risolvere il problema by streaming fast-moving data nel bulk storage per un successivo batch processing. 
L'importanza della velocità sta nella velocità totale del feedback loop che coinvolge data in input per decisioni.
![[Pasted image 20250402111542.png]]
#### Variety
> Quanti tipi di dati ci sono? (formato, struttura e grandezza)

La Varietà indica i diversi tipi e la diversa natura dei dati che vengono analizzati. Raramente i dati sono perfettamente ordinati e pronti al processing poiché derivano da diverse sorgenti. Tutte le piattaforme big data devono essere flessibili per gestire queste varietà, considerando inoltre l'evoluzione imprevedibile dei dati.
#### Veracity
> Quanto precisi e veritieri sono i dati?

Indicano la qualità e la veriditicità dei dati collezionati. 


> [!NOTE] Due Approcci
> Gli approcci per gestire queste sfide possono essere raggruppate in due categorie:
> - **Metodologiche**: include tutte le decisione design che coinvolgono l'architettura, gli algoritmi, lo storage schema e i cleaning methods.
> - **Tecnologiche**: include tutti i design di aspetti associati al DBMS da utilizzare, la configurazione cluster da adottare, e l'affidabilità delle soluzioni.

---
# Graphs for Big Data

#### Caso d'uso (Esempio)
Sei un poliziotto che deve rintracciare un criminale attraverso le torrette telefoniche. L'obiettivo è monitorare i dati delle torrette per creare un modello predittivo e identificare le locazioni più rilevanti secondo il soggetto in osservazione.

Utilizzeremo grafi per organizzare i dati e creare graph-based materialized view dei movimenti del soggetto.
Il grafo risultante viene analizzato con un algoritmo che identifica clusters di posizioni. Queste posizioni vengono utilizzate dall'algoritmo successivo per costruire un modello predittivo.
![[Pasted image 20250402110352.png]]
**Approccio Generale**:
- Numerosi dati in forma di eventi (spostamento tra torrette).
- I dati sono distribuiti diverse sorgenti data (torrette).
- I dati necessitano di essere aggregati e organizzati in una forma che semplifica i processi e analisi future.
- Dalla prima aggregazione, abbiamo creato alcune views (foto precedente con clusters).
- Servono alcune real-time view per gli ultimi spostamenti per reagire velocemente.

**Problemi Architetturali**:
- Gli eventi di log delle torrette presentano dati grezzi (*raw*), immutabili e veri. 
- Diverse view create in funzione all'algoritmo di analisi.
- La view-building process opera generalmente su tutto il dataset, e questo può richiedere tempo in contesti grandi. Il tempo richiesto crea un gap tra i precedenti eventi che vengono elaborati e quelli attuali in real-time.
- Per avere real-time, c'è bisogno di uno **streaming process** che legge gli eventi e accoda le informazioni.
---
## Architettura Lambda
![[Pasted image 20250402111621.png|500]]
I problemi architetturali possono essere indirizzati dall'Architettura Lambda, la quale concepisce il sistema big data come una serie di 3 livelli:
- **Batch Layer**: strato che elabora i dati in blocchi (batch) e fornisce analisi storiche complete.
- **Serving Layer**: strato che memorizza e serve i dati elaborati agli utenti per le queries.
- **Speed Layer**: strato che processa i dati in streaming per renderli disponibili quasi in tempo reale.
Ciascun livello soddisfa un subset dei requisiti e si basa sulla funzionalità fornita dagli altri strati.
L'Architettura Lambda contiene una tradizionale batch data pipeline e una pipeline fast streaming per dati real-time, ed un livello serving per queries.

> L'Architettura Lambda è una tecnologia agnostica incentrata sul gestire enormi quantità di dati favorendo sia metodi di batch che di stream-processing. Cerca di bilanciare le preoccupazioni intorno a **latency**, **data consistency**, **scalability**, **fault tolerance** e **human fault tolerance** utilizzando batch processing per fornire comprensibili e accurate views di data, mentre si utilizza simultaneamente real-time stream processing.

- **Latency**: i dati grezzi vengono indicizzati nel livello di serving in modo che gli utenti finali possano interrogarli e analizzarli. Poiché l'indicizzazione batch richiede tempo, c'è un gap di tempo in cui i dati non sono ancora disponibili per l'analisi. Lo speed layer utilizza tecnologie di stream processing per indicizzare immediatamente i dati recenti, riducendo il periodo di indisponibilità e migliorando la latenza.
- **Data Consistency**: Lambda riduce il rischio di inconsistenza dei dati nei sistemi distribuiti, poiché elabora i dati in modo sequenziale. Questo evita sovrapposizioni e garantisce che i dati riflettano sempre lo stato più recente sia nel batch che nello speed.
- **Scalability**: Lambda è basata su tecnologie distribuite e scalabili, il che significa che è possibile espandere la capacità aggiungendo nuovi nodi. Questo vale per tutte le fasi del processo: sorgente dati, batch, serving e speed layer.
- **Fault Tolerance**: essendo costruita su sistemi distribuiti, Lambda garantisce continuità anche in casi di guasti hw. Se si verifica un errore nell'indicizzazione, è possibile eseguire nuovamente il processo nel batch/serving layer mentre lo speed continua a elaborare i dati recenti.
- **Human Fault Tolerance**: i dati grezzi vengono sempre conservati, consentendo di ricreare gli indici in caso di bug o errori di omissione nel codice di indicizzazione. Se necessario, il codice può essere corretto e l'intero dataset può essere rielaborato per garantire dati sempre affidabili.
#### Querying
- Possiamo eseguire **query on the fly** (al volo) -> questo approccio è generalmente impossibile a causa della quantità di dati da elaborare e la natura delle fonti di dati da accedere.
- Approccio alternativo è **precomputare il risultato della query** o un valore intermedio per velocizzare i risultati della query finale.
Chiamiamo il query result, intermedio o finale, **batch view**.

![[Pasted image 20250402115322.png]]
Tutti i dati nel formato *raw* sono memorizzati nel **Batch Layer**. Questo livello è responsabile per l'accesso ai dati raw e le batch view computation e extraction.
Le view risultanti vengono memorizzate nel **Serving Layer**, dove verranno indicizzate in maniera specifica e accedute durante le queries. 
Il serving layer viene aggiornato ogni volta che il batch layer finisce di precomputare una batch view.

![[Pasted image 20250402115745.png]]
Lo **Speed Layer** fornisce delle views degli ultimi dati, riducendo il gap tra il batch layer e gli ultimi dati arrivati. Questo livello guarda solo gli ultimi dati, mentre il batch layer guarda tutti i dati.
Questo permette di rispondere più velocemente agli ultimi cambiamenti facilitando e migliorando le analisi.

#### Indexing
I livelli batch e serving continuamente indicizza i dati in entrata. 
I dati vengono indicizzati simultaneamente nel livello serving e speed.
Una volta indicizzati, i dati sono accessibili dalle query e quindi rimuovo questi dati dallo speed layer.
![[Pasted image 20250402120505.png]]

---
# Graphs for Master Data Management
(da pag 40 a 56)

---
# Graphs Data Management
Utilizzare grafi in ML projects richiede memorizzazione, accesso, query e gestione di ciascuno di questi grafi: questo è chiamato **Graph Data Management**.
- **Modeling**: 
	- Lo stesso aspetto della realtà può essere mappato in molteplici modi in un graph model.
	- "Schemaless" natura dei grafi.
	- Il design del modello influenza le performance di tutte le queries e analisi.
- **Storage**:
	- Persistent data storage, memory use, caching, query languages, data integrity e consistency.
	- In aggiunta: scalabilità, affidabilità e performance.
- **Processing**:
	- Frameworks (tools, linguaggi query e algoritmi) per processare e analizzare grafi.
	- Di solito, utilizzare più macchine migliora le performance.
	- Alcune features di processo, come linguaggio di query, sono accessibili nel DBMS stesso.

Aspetti tecnologici associati alla gestione di grafi sono importanti in progetti *machine learning*, nei quali è necessario manipolare, memorizzare e accedere dati reali.
In molti casi, è necessario lavorare con grandi moli di dati, **problemi legati alla scalabilità** sono cruciali:
- **Sharding**: suddividere i dati orizzontalmente tra i diversi servers.
- **Replication**: duplicare i dati su diversi server, per una maggiore accessibilità e per scopi di scalabilità.
- **Native** **vs non native graph databases**: problemi di performance durante lo storage/querying.
- Label property graphs.

## Sharding
Guardando applicazioni con grandi quantità di dati da un punto di vista puramente della memoria, le principali sfide sono:
- **Volume**: il volume dei dati coinvolti è così grande da non riuscire a memorizzare tutto su una singola macchina.
- **Velocity**: una singola macchina può servire solo un numero limitato di users allo stesso momento.

**Sharding**: un grande dataset viene suddiviso, e i subset sono distribuiti lungo diversi server.
**Sharding** **strategy**: determina quel partizione dei dati dovrebbe essere inviata a quale frammento (server).
![[Pasted image 20250408132232.png]]

**Attraversamento delle relazioni in mezzo a due shards** sono molto costose computazionalmente e in termini di performance.
![[Pasted image 20250408154649.png|400]]
**Overloading un singolo shard**: nodi associati sono memorizzati sullo stesso shard permettendo un attraversamento più rapido, ma il carico sugli shard è altamente sbilanciato. Questo può provocare tempi di accesso imprevedibili, rendendo questa soluzione inconveniente da implementare.
![[Pasted image 20250408160101.png|400]]

### Sharding Techniques
- **Application Level Sharding**:
	- Lo Sharding dei dati è compiuto lato applicativo utilizzando le conoscenze del dominio specifico (per esempio suddividere i dati in base alla geo-localizzazione degli utenti).
	- Lo Sharding si può basare su diverse tipologie di analisi o processi che il grafo deve eseguire sui dati.
	- Ciascuno Shard contiene tutti i dati richiesti per eseguire l'algoritmo, e alcuni nodi possono essere replicati tra gli Shards.
![[Pasted image 20250408161112.png|500]]
- **Aumentare la RAM o utilizzare Cache Sharding**: 
	- E' possibile scalare il server verticalmente, aggiungendo più RAM così che tutti il DB stia in memoria.
	- Questa soluzione rende l'attraversamento del grafo estremamente veloce ma è strettamente impossibili per enormi DB.
	- **Cache Sharding**: mantiene prestazioni elevate con set di dati che superano di gran lunga la capacità di memoria. Non memorizza l'intero dataset in ciascuna istanza DB.
	- Per implementare la condivisione della cache, partizioniamo il carico di lavoro di ciascuna istanza del DB, per aumentare la probabilità di raggiungere una cache calda per una determinata richiesta.
- **Replication** (di seguito)

## Replication
E' possibile ottenere una maggiore scalabilità del DB aggiungendo più copie identiche (in più server) del DB che agiscono come followers con accessi read-only.
La Data Replication consiste nel mantenere copie multiple, definite replicas, su computer separati. La Replication ha diversi scopi:
- **System Availability**: la replicazione rimuove single points of failure permettendo l'accessibilità di data items da multipli siti. Anche quando dei cluster vanno down, i dati dovrebbero comunque rimanere accessibili.
- **Performance**: la replicazione riduce la latenza allocando i dati più vicini agli access points.
- **Scalability**: la replicazione permette ai sistemi di crescere, sia geograficamente che in termini di numero di richieste di accesso, mantenendo tempi di risposta accettabili.
- **Application Requirements**: come parte di specifiche operazionali, applicazioni possono richiedere multiple copie di dati da mantenere.
#### Sincronizzazione
**Mantenere le diverse copie sincronizzate** è una challenge. Una decisione fondamentale nel design del protocollo di replicazione è dove gli aggiornamenti del DB sono inizialmente eseguiti. Le tecniche possono essere caratterizzate come segue:
- **Centralizzato** -> se il primo aggiornamento avviene su una master copy. 
- **Distribuito** -> se è permesso l'update di qualunque replica.
![[Pasted image 20250408130916.png]]
*Un nodo master è tipicamente responsabile del processo di aggiornamento dei dati. Anche quando una replica permette la scrittura, queste operazioni devono passare da un master per essere eseguite.*

#### Casi d'uso:
- Nell'esempio delle torrette cellulari: un grafo viene creato per monitorare ciascun soggetto, così la ML model produce multipli grafi indipendenti che vengono accessi in modo isolato. In questo caso l'application level sharding è un task semplice perché i grafi sono isolati. Generalizzando, nello scenario graph based Lambda Architecture, con multiple graph views create sullo stesso dataset, possiamo memorizzare le views in istanze multiple di database perchè sono accesso in maniera indipendente.
- Nella fraud detection: l'operazione di sharding sarà complicata perché in teoria tutti i nodi possono essere connessi. Possono essere applicate delle euristiche per ridurre il cross-shard traversal o per mantenere i nodi che sono frequentemente acceduti insieme nella stessa shard, ma il grafo non può essere diviso in diversi grafi isolati come nel caso precedente. **In questi casi un'altra opzione è quella di replicare (duplicare) per scalare le performance in lettura e la velocità dei tempi di analisi.**

## Native vs non native graph Databases